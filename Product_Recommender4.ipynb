{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Product Recommender.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "history_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GitDashHero/GitDashHero/blob/main/Product_Recommender4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbDSs2p9CTIN"
      },
      "source": [
        "## **PRODUCT RECOMMENDER SYSTEM - CSDA 1040**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USFFlQzTCifz"
      },
      "source": [
        "### **Context: Building a Product Recommender System**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbyEWEM6DdKZ"
      },
      "source": [
        "Everyday millions of products get sold online. It has been established that products recommended to users based on popularity and other metrics on e-commerce websites leads to enhanced user experience. Most popular e-commerce website boost their average order value and also increases revenues significantly thereby improves conversion. Recommender systems are among the most visible and successful applications of Articial Intelligence and Machine Learning technology in practice. Nowadays, such systems accompany us\n",
        "through our daily online lives — for example on e-commerce sites, on media streaming platforms, or in social networks. They help us by suggesting things that are assumed to be of interest to us and which we are correspondingly likely to inspect, consume, or purchase."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0YZAIlcFoJx"
      },
      "source": [
        "**Data Source: Source** - Amazon Reviews data (http://jmcauley.ucsd.edu/data/amazon/) The repository has several datasets. For this case study, we are using the Electronics dataset.\n",
        "Learning Outcomes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGTxhX5XGkvI"
      },
      "source": [
        "**BUSINESS PROBLEM:**\n",
        "\n",
        "As a business that is invested in online sales, it has become imperative to build a product recommender system. Customers that are accustomed to online shopping have come to expect a level of personalization and recommendation to enhance their experience and might move away to websites that are more perceptive to their needs.\n",
        "\n",
        "a) Helps User find the right type of product more easily which leads to better levels of engagement\n",
        "\n",
        "b) Also helps the business use cross-sell, upsell and entice customers which leads to increased sales\n",
        "\n",
        "c) Leads to a personalized experience "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFp8xxhBGk60"
      },
      "source": [
        "\n",
        "**ANALYTICAL OBJECTIVE**\n",
        "\n",
        "Build a Recommender Model that recommends products to users either based on popularity or ratings to increase customer engagement and drive sales. \n",
        "\n",
        "There are different types of recommender models based on popularity, user based, content based recommendation, collaborative filtering.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQUfJbd_B7_O"
      },
      "source": [
        "# Importing Libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import os\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "import math\n",
        "import json\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import scipy.sparse\n",
        "from scipy.sparse import csr_matrix\n",
        "from scipy.sparse.linalg import svds\n",
        "import warnings; warnings.simplefilter('ignore')\n",
        "%matplotlib inline\n",
        "\n",
        "# suppress display of warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# display all dataframe columns\n",
        "pd.options.display.max_columns = None\n",
        "\n",
        "# to set the limit to 3 decimals\n",
        "pd.options.display.float_format = '{:.7f}'.format\n",
        "\n",
        "# display all dataframe rows\n",
        "pd.options.display.max_rows = None\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "lh0cdlZFNTNb",
        "outputId": "9aaff0b3-9231-47ce-c33c-b93174893e34"
      },
      "source": [
        "# Loading Data with headers and display\n",
        "electronics_data = pd.read_csv(\"ratings_Electronics.csv\", names=['userId', 'productId','Rating','timestamp'])\n",
        "electronics_data = electronics_data.iloc[1:]\n",
        "electronics_data.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>productId</th>\n",
              "      <th>Rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A2CX7LUOHB2NDG</td>\n",
              "      <td>0321732944</td>\n",
              "      <td>5.0000000</td>\n",
              "      <td>1341100800.0000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A2NWSAGRHCP8N5</td>\n",
              "      <td>0439886341</td>\n",
              "      <td>1.0000000</td>\n",
              "      <td>1367193600.0000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A2WNBOD3WNDNKT</td>\n",
              "      <td>0439886341</td>\n",
              "      <td>3.0000000</td>\n",
              "      <td>1374451200.0000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A1GI0U4ZRJA8WN</td>\n",
              "      <td>0439886341</td>\n",
              "      <td>1.0000000</td>\n",
              "      <td>1334707200.0000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>A1QGNMC6O1VW39</td>\n",
              "      <td>0511189877</td>\n",
              "      <td>5.0000000</td>\n",
              "      <td>1397433600.0000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           userId   productId    Rating          timestamp\n",
              "1  A2CX7LUOHB2NDG  0321732944 5.0000000 1341100800.0000000\n",
              "2  A2NWSAGRHCP8N5  0439886341 1.0000000 1367193600.0000000\n",
              "3  A2WNBOD3WNDNKT  0439886341 3.0000000 1374451200.0000000\n",
              "4  A1GI0U4ZRJA8WN  0439886341 1.0000000 1334707200.0000000\n",
              "5  A1QGNMC6O1VW39  0511189877 5.0000000 1397433600.0000000"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8c9Od9vYHFL"
      },
      "source": [
        "**DATA EXPLORATION**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMGxaOy8X7wT",
        "outputId": "34eca7a8-15d7-4ce8-9d3a-caf98bcd3769"
      },
      "source": [
        "# Datatypes\n",
        "\n",
        "electronics_data.info()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3192096 entries, 1 to 3192096\n",
            "Data columns (total 4 columns):\n",
            " #   Column     Dtype  \n",
            "---  ------     -----  \n",
            " 0   userId     object \n",
            " 1   productId  object \n",
            " 2   Rating     float64\n",
            " 3   timestamp  float64\n",
            "dtypes: float64(2), object(2)\n",
            "memory usage: 97.4+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpxZpQMvX77C",
        "outputId": "cb1210d1-6178-42d3-fe08-a326fffd4d1a"
      },
      "source": [
        "# Shape of the data\n",
        "electronics_data.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3192096, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8eQG4-tbX8Ek",
        "outputId": "81683c08-59db-46d6-9c83-3c5c98a8db1a"
      },
      "source": [
        "# More on our data\n",
        "electronics_data.describe()['Rating'].T"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count   3192095.0000000\n",
              "mean          3.9752777\n",
              "std           1.4021868\n",
              "min           1.0000000\n",
              "25%           3.0000000\n",
              "50%           5.0000000\n",
              "75%           5.0000000\n",
              "max           5.0000000\n",
              "Name: Rating, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtY4_9VhX8Ng",
        "outputId": "613e3cc9-1fcc-40e4-c434-caac9989faca"
      },
      "source": [
        "# Checking for any null or missing values\n",
        "print('Number of missing values across columns: \\n',electronics_data.isnull().sum())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of missing values across columns: \n",
            " userId       0\n",
            "productId    0\n",
            "Rating       1\n",
            "timestamp    1\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iw7VE_qAZNEg",
        "outputId": "b6095b8a-fd4a-4e20-f47d-3ada97114cfb"
      },
      "source": [
        "#Find the minimum and maximum ratings\n",
        "print('Minimum rating is: %d' %(electronics_data.Rating.min()))\n",
        "print('Maximum rating is: %d' %(electronics_data.Rating.max()))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minimum rating is: 1\n",
            "Maximum rating is: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_s_9pa84a6ys"
      },
      "source": [
        "**DATA DISTRIBUTION**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zcuu-wNfZjH"
      },
      "source": [
        "\n",
        "sns.pairplot(electronics_data, diag_kind= 'kde')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fiCo7dzoX8X1"
      },
      "source": [
        "# Checking the distribution of the ratings\n",
        "rating_counts = pd.DataFrame(electronics_data['Rating'].value_counts()).reset_index()\n",
        "rating_counts.columns = ['Labels', 'Ratings']\n",
        "rating_counts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emjJwbphkG5h"
      },
      "source": [
        "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(15,7))\n",
        "sns.countplot(electronics_data['Rating'], ax=ax1)\n",
        "ax1.set_xlabel('Rating Distribution', fontsize=10)\n",
        "ax1.set_ylabel('Count', fontsize=10)\n",
        "\n",
        "\n",
        "explode = (0.1, 0, 0.1, 0, 0)\n",
        "ax2.pie(rating_counts[\"Ratings\"], explode=explode, labels=rating_counts.Labels, autopct='%1.2f%%',\n",
        "        shadow=True, startangle=70)\n",
        "ax2.axis('equal')\n",
        "plt.title(\"Rating Ratio\")\n",
        "plt.legend(rating_counts.Labels, loc=3)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZCB8bvVf1MI"
      },
      "source": [
        "**OBSERVATIONS:**\n",
        "\n",
        "We can see that most customers provide a rating of \"5\". Very few customers have given a rating of \"2\". \n",
        "\n",
        "From the barplot and pia chart we can clearly see that approx 55% of data have 5 rating followed by 4(approx 19%). Least number of people have given 2 rating. \n",
        "\n",
        "Either most products are liked by customers or there is more to investigate such as dropping of reviews by bots or promotional events. \n",
        "\n",
        "Are customers asked for feedback, if they give a lower rating thus making it easier to go with a rating of \"5\"?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0h_5KZjbC_r"
      },
      "source": [
        "**UNIQUE USERS AND NUMBER OF UNIQUE PRODUCTS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0767NVZ3j4mN"
      },
      "source": [
        "electronics_data.productId = electronics_data.productId.fillna('')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6bglPj2a4b9"
      },
      "source": [
        "print(\"\\nTotal no of Ratings :\",electronics_data.shape[0])\n",
        "print(\"Total No of Users   :\", len(np.unique(electronics_data.userId)))\n",
        "print(\"Total No of Products  :\", len(np.unique(electronics_data.productId)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gC8gIQN8a4nW"
      },
      "source": [
        "#Dropping the Timestamp Column and it is not needed for our analysis\n",
        "\n",
        "electronics_data.drop(['timestamp'], axis=1,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-UwKu3H-lu1s"
      },
      "source": [
        "**POPULARITY BASED RECOMMENDER**\n",
        "\n",
        "Popularity based recommendation system uses the most frequently sold items to drive sales. For example, if any product which is usually bought by every new user then there are chances that it may suggest that item to the user who just signed up.\n",
        "\n",
        "The problems with popularity based recommendation system is that the personalization is not available with this method i.e. even though you know the behaviour of the user you cannot recommend items accordingly.\n",
        "\n",
        "This is good for new users when data is not available on their preferences.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWbWRTFya4zD"
      },
      "source": [
        "#  Taking Subset of users who have given 50 or more number of ratings\n",
        "users_counts = electronics_data['userId'].value_counts().rename('users_counts')\n",
        "users_data   = electronics_data.merge(users_counts.to_frame(),\n",
        "                                left_on='userId',\n",
        "                                right_index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LTygCqkltfW"
      },
      "source": [
        "subset_df = users_data[users_data.users_counts >= 50]\n",
        "subset_df.tail()\n",
        "\n",
        "# Customers who have rated more than 50 products. These customers seem like they are regular buyers and provide regular feedback."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMXbusE6naCX"
      },
      "source": [
        "**Resolving the \"Grey Sheep\" Problem:**\n",
        "\n",
        "\"Recommender Systems have been successfully applied to alleviate the information overload problem and assist the process of decision making. Collaborative filtering, as one of the most popular recommendation algorithms, has been fully explored and developed in the past two decades. However, one of the challenges in collaborative filtering, the problem of \"Grey Sheep\" user, is still under investigation. \"Grey Sheep\" users is a group of the users who have special tastes and they may neither agree nor disagree with the majority of the users. The identification of them becomes a challenge in collaborative filtering, since they may introduce difficulties to produce accurate collaborative recommendations\" (Source:https://dl.acm.org/doi/abs/10.1145/3125649.3125651)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiJGGXQVmjz-"
      },
      "source": [
        "# We resolve the \"Grey Sheep\" Problem by taking a subset of products that have 10 or more ratings. \n",
        "# This will ensure that these are commonly purchased and rated.\n",
        "product_rating_counts = subset_df['productId'].value_counts().rename('product_rating_counts')\n",
        "product_rating_data   = subset_df.merge(product_rating_counts.to_frame(),\n",
        "                                left_on='productId',\n",
        "                                right_index=True)\n",
        "product_rating_data = product_rating_data[product_rating_data.product_rating_counts >= 10]\n",
        "product_rating_data.tail()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zm8tv_0fqjU2"
      },
      "source": [
        "no_of_ratings_per_product = product_rating_data.groupby(by='productId')['Rating'].count().sort_values(ascending=False)\n",
        "\n",
        "fig = plt.figure(figsize=plt.figaspect(.5))\n",
        "ax = plt.gca()\n",
        "plt.plot(no_of_ratings_per_product.values)\n",
        "plt.title('# RATINGS per Product')\n",
        "plt.xlabel('Product')\n",
        "plt.ylabel('No of ratings per product')\n",
        "ax.set_xticklabels([])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oF9mSGSYq7d-"
      },
      "source": [
        "#Average rating of the product \n",
        "\n",
        "product_rating_data.groupby('productId')['Rating'].mean().head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "det14Bxxq7p2"
      },
      "source": [
        "product_rating_data.groupby('productId')['Rating'].mean().sort_values(ascending=False).head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrRTaJ1aq7zG"
      },
      "source": [
        "#Top Products with maximum ratings of \"5\"\n",
        "\n",
        "product_rating_data.groupby('productId')['Rating'].count().sort_values(ascending=False).head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4kktTQYq726"
      },
      "source": [
        "ratings_mean_count = pd.DataFrame(product_rating_data.groupby('productId')['Rating'].mean())\n",
        "ratings_mean_count['rating_counts'] = pd.DataFrame(product_rating_data.groupby('productId')['Rating'].count())\n",
        "ratings_mean_count.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZ9FZxv5q77f"
      },
      "source": [
        "plt.figure(figsize=(8,6))\n",
        "plt.rcParams['patch.force_edgecolor'] = True\n",
        "ratings_mean_count['rating_counts'].hist(bins=20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BL0MNphx0OVc"
      },
      "source": [
        "**OBSERVATION:**\n",
        "\n",
        "We see that the most customers have reviewed the top 25 products. This leads us to the conclusion that this seems to be the most popular product."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHsXvk-aq7-M"
      },
      "source": [
        "plt.figure(figsize=(8,6))\n",
        "plt.rcParams['patch.force_edgecolor'] = True\n",
        "ratings_mean_count['Rating'].hist(bins=50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nT13Jbh2DcH"
      },
      "source": [
        "**OBSERVATION**\n",
        "\n",
        "Here we see that the items with most ratings seem to be popular and consistently score between Rating \"4\" to Rating \"5\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKsh2tJjq8Bd"
      },
      "source": [
        "# Lets see the data on a jointplot\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.rcParams['patch.force_edgecolor'] = True\n",
        "sns.jointplot(x='Rating', y='rating_counts', data=ratings_mean_count, alpha=0.4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIzZtRjqq8Fm"
      },
      "source": [
        "popular_products = pd.DataFrame(product_rating_data.groupby('productId')['Rating'].count())\n",
        "most_popular = popular_products.sort_values('Rating', ascending=False)\n",
        "most_popular.head(10).plot(kind = \"bar\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MWdzzHv3gS0"
      },
      "source": [
        "The above chart shows us the Top 10 Recommended Products based on popularity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BKtftcA5gxy"
      },
      "source": [
        "**DATA PREPARATION**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZEH4gSOq8Jy"
      },
      "source": [
        "df1=product_rating_data.copy()\n",
        "df2 = df1.drop(['users_counts', 'product_rating_counts'], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nvHvgewq8MB"
      },
      "source": [
        "df2.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "199celAm7x_8"
      },
      "source": [
        "!pip3 install numpy\n",
        "!pip3 install scikit-surprise"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwAR5Nrz61bW"
      },
      "source": [
        "from collections import defaultdict\n",
        "from surprise import KNNWithMeans\n",
        "from surprise import SVD, SVDpp\n",
        "from surprise import KNNBaseline\n",
        "from surprise import KNNBasic\n",
        "from surprise import KNNWithZScore\n",
        "from surprise import BaselineOnly\n",
        "from surprise import Dataset\n",
        "from surprise import Reader\n",
        "from surprise import accuracy\n",
        "from surprise.model_selection import train_test_split\n",
        "from surprise.model_selection import cross_validate\n",
        "from surprise.model_selection import KFold\n",
        "from surprise.model_selection import GridSearchCV\n",
        "\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJy33egTq8Pv"
      },
      "source": [
        "# Spliting the data randomly into train and test dataset. (Split it in 70/30 ratio)\n",
        "\n",
        "k = 5 \n",
        "#(To Get top - K ( K = 5) recommendations)\n",
        "reader = Reader(rating_scale=(1, 5))\n",
        "surprise_data = Dataset.load_from_df(df2[['userId', 'productId', 'Rating']], reader)\n",
        "trainset, testset = train_test_split(surprise_data, test_size=.30, random_state=7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHyieHL28TBS"
      },
      "source": [
        "**DATA MODELING**\n",
        "\n",
        "Here we will try two types of Popularity Recommender Models - \n",
        "\n",
        "1) Using Mean Product Rating\n",
        "\n",
        "2) Using Ranking Based Rating"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7m4dPGSW9Fk5"
      },
      "source": [
        "# 1) Using Mean Product Rating\n",
        "df2.groupby('productId')['Rating'].mean().head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FoUOQsYK9F_f"
      },
      "source": [
        "df2.groupby('productId')['Rating'].mean().sort_values(ascending=False).head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9FduWyd9y2x"
      },
      "source": [
        "prod_rating_count = pd.DataFrame(df2.groupby('productId')['Rating'].mean().sort_values(ascending=False))\n",
        "prod_rating_count['prod_rating_count'] = pd.DataFrame(df2.groupby('productId')['Rating'].count())\n",
        "prod_rating_count.head(k)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TM0PXDAa9zLT"
      },
      "source": [
        "basic_poplurity_model = prod_rating_count.sort_values(by=['prod_rating_count'], ascending=False)\n",
        "basic_poplurity_model.head(k)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wk1gwARf-KgJ"
      },
      "source": [
        "These are the TOP 5 popular products that would be recommended based on Mean Product Rating"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y23UrgTN-XTB"
      },
      "source": [
        "2) Ranking Based Rating"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0H1LOLGU9zRR"
      },
      "source": [
        "df2_grouped = df2.groupby('productId').agg({'userId': 'count'}).reset_index()\n",
        "df2_grouped.rename(columns = {'userId': 'Score'},inplace=True)\n",
        "df2_grouped.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgiiaLw-9zaj"
      },
      "source": [
        "#Sort the products on recommendation score \n",
        "df2_sort = df2_grouped.sort_values(['Score', 'productId'], ascending = [0,1]) \n",
        "      \n",
        "#Generate a product rank based upon score \n",
        "df2_sort['Rank'] = df2_sort['Score'].rank(ascending=0, method='first') \n",
        "          \n",
        "#Get the top 5 recommendations \n",
        "popularity_recommendations = df2_sort.head(k) \n",
        "popularity_recommendations "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xcsXTOdJPfo"
      },
      "source": [
        "**MODEL DEPLOYMENT AND EVALUATION**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaqXUHaN9zio"
      },
      "source": [
        "# Using popularity based recommender model to make predictions and find recommendations for random list of users with inferences\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "def recommend(userId):     \n",
        "    user_recommendations = popularity_recommendations \n",
        "          \n",
        "    #Adding user_id column for which the recommendations are being generated \n",
        "    user_recommendations['userID'] = userId \n",
        "      \n",
        "    #Bringing user_id column to the front \n",
        "    cols = user_recommendations.columns.tolist() \n",
        "    cols = cols[-1:] + cols[:-1] \n",
        "    user_recommendations = user_recommendations[cols] \n",
        "          \n",
        "    return user_recommendations "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsk0bDvf9zos"
      },
      "source": [
        "find_recom = [15,121,55,230,477]   # This list is user choice.\n",
        "for i in find_recom:\n",
        "    print(\"Here is the recommendation for the userId: %d\\n\" %(i))\n",
        "    print(recommend(i))    \n",
        "    print(\"\\n\") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBhhKcWkg-CG"
      },
      "source": [
        "import pickle\n",
        "pickle.dump(popularity_recommendations ,open('mostpopular.pkl','wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNfXgiPgHijA"
      },
      "source": [
        "**NOTE:**\n",
        "\n",
        "Since this is a popularity-based recommender model, recommendations remain the same for all users. We predict the products based on the popularity. It is not personalized to the user."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gw5URhGlKEFS"
      },
      "source": [
        "**COLLABORATIVE FILTER MODELLING**\n",
        "\n",
        "We will use the SVD and KNN based modeling to find the closest product to the chosen product and also closest User Profile to the current User Profile\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbgZRy48Sa7M"
      },
      "source": [
        "**SVD**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0pjhw45SfAz"
      },
      "source": [
        "# Creating Model using best parameters\n",
        "svd_model = SVD(n_epochs=20, lr_all=0.005, reg_all=0.2)\n",
        "\n",
        "# Training the algorithm on the trainset\n",
        "svd_model.fit(trainset)\n",
        "\n",
        "\n",
        "# Predicting for test set\n",
        "predictions_svd = svd_model.test(testset)\n",
        "\n",
        "# Evaluating RMSE, MAE of algorithm SVD on 5 split(s) by cross validation\n",
        "svd_cv = cross_validate(svd_model, surprise_data, measures=['RMSE', 'MAE'], cv=5, verbose=True)\n",
        "\n",
        "# Storing Crossvalidation Results in dataframe\n",
        "svd_df = pd.DataFrame.from_dict(svd_cv)\n",
        "svd_described = svd_df.describe()\n",
        "cv_results = pd.DataFrame([['SVD', svd_described['test_rmse']['mean'], svd_described['test_mae']['mean'], \n",
        "                           svd_described['fit_time']['mean'], svd_described['test_time']['mean']]],\n",
        "                            columns = ['Model', 'RMSE', 'MAE', 'Fit Time', 'Test Time'])\n",
        "# get RMSE\n",
        "print(\"\\n\\n==================== Model Evaluation ===============================\")\n",
        "accuracy.rmse(predictions_svd, verbose=True)\n",
        "print(\"=====================================================================\")\n",
        "cv_results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDXaIcHXS_vs"
      },
      "source": [
        "**Comment:** Here we can see that the RMSE of testset and complete dataset found from cross_validation is almost same and it seems like our model is performing well on trainset and testset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLYX-c1bTE9W"
      },
      "source": [
        "**SVD++**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbFjLXlPTTlp"
      },
      "source": [
        "# Creating Model using best parameters\n",
        "svdpp_model = SVDpp(n_epochs=25, lr_all=0.01, reg_all=0.4)\n",
        "\n",
        "# Training the algorithm on the trainset\n",
        "svdpp_model.fit(trainset)\n",
        "\n",
        "\n",
        "# Predicting for test set\n",
        "predictions_svdpp = svdpp_model.test(testset)\n",
        "\n",
        "# Evaluating RMSE, MAE of algorithm SVDpp on 5 split(s) by cross validation\n",
        "svdpp_cv = cross_validate(svdpp_model, surprise_data, measures=['RMSE', 'MAE'], cv=5, verbose=True)\n",
        "\n",
        "# Storing Crossvalidation Results in dataframe\n",
        "svdpp_df = pd.DataFrame.from_dict(svdpp_cv)\n",
        "svdpp_described = svdpp_df.describe()\n",
        "svdpp_cv_results = pd.DataFrame([['SVD++', svdpp_described['test_rmse']['mean'], svdpp_described['test_mae']['mean'], \n",
        "                           svdpp_described['fit_time']['mean'], svdpp_described['test_time']['mean']]],\n",
        "                            columns = ['Model', 'RMSE', 'MAE', 'Fit Time', 'Test Time'])\n",
        "\n",
        "cv_results = cv_results.append(svdpp_cv_results, ignore_index=True)\n",
        "# get RMSE\n",
        "print(\"\\n\\n==================== Model Evaluation ===============================\")\n",
        "accuracy.rmse(predictions_svdpp, verbose=True)\n",
        "print(\"=====================================================================\")\n",
        "cv_results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axMvqYEjLtH-"
      },
      "source": [
        "**KNN BASIC**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QHB7xHqLxTf"
      },
      "source": [
        "knn_param_grid = {'bsl_options': {'method': ['als', 'sgd'],\n",
        "                              'reg': [1, 2]},\n",
        "              'k': [15, 20, 25, 30, 40, 50, 60],\n",
        "              'sim_options': {'name': ['msd', 'cosine', 'pearson_baseline']}\n",
        "              }\n",
        "\n",
        "knnbasic_gs = GridSearchCV(KNNBasic, knn_param_grid, measures=['rmse', 'mae'], cv=5, n_jobs=5)\n",
        "knnmeans_gs = GridSearchCV(KNNWithMeans, knn_param_grid, measures=['rmse', 'mae'], cv=5, n_jobs=5)\n",
        "knnz_gs     = GridSearchCV(KNNWithZScore, knn_param_grid, measures=['rmse', 'mae'], cv=5, n_jobs=5)\n",
        "\n",
        "\n",
        "knnbasic_gs.fit(surprise_data)\n",
        "knnmeans_gs.fit(surprise_data)\n",
        "knnz_gs.fit(surprise_data)\n",
        "\n",
        "# best RMSE score\n",
        "print(knnbasic_gs.best_score['rmse'])\n",
        "print(knnmeans_gs.best_score['rmse'])\n",
        "print(knnz_gs.best_score['rmse'])\n",
        "\n",
        "# combination of parameters that gave the best RMSE score\n",
        "print(knnbasic_gs.best_params['rmse'])\n",
        "print(knnmeans_gs.best_params['rmse'])\n",
        "print(knnz_gs.best_params['rmse'])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVP7nggCLxaH"
      },
      "source": [
        "# Creating Model using best parameters\n",
        "knnBasic_model = KNNBasic(k=50, sim_options={'name': 'cosine', 'user_based': False})\n",
        "\n",
        "# Training the algorithm on the trainset\n",
        "knnBasic_model.fit(trainset)\n",
        "\n",
        "# Predicting for test set\n",
        "prediction_knnBasic = knnBasic_model.test(testset)\n",
        "\n",
        "# Evaluating RMSE, MAE of algorithm KNNBasic on 5 split(s)\n",
        "knnBasic_cv = cross_validate(knnBasic_model, surprise_data, measures=['RMSE', 'MAE'], cv=5, verbose=True)\n",
        "\n",
        "# Storing Crossvalidation Results in dataframe\n",
        "knnBasic_df = pd.DataFrame.from_dict(knnBasic_cv)\n",
        "knnBasic_described = knnBasic_df.describe()\n",
        "knnBasic_cv_results = pd.DataFrame([['KNNBasic', knnBasic_described['test_rmse']['mean'], knnBasic_described['test_mae']['mean'], knnBasic_described['fit_time']['mean'], knnBasic_described['test_time']['mean']]],\n",
        "columns = ['Model', 'RMSE', 'MAE', 'Fit Time', 'Test Time'])\n",
        "cv_results = cv_results.append(knnBasic_cv_results, ignore_index=True)\n",
        "\n",
        "# get RMSE\n",
        "print(\"\\n\\n==================== Model Evaluation ===============================\")\n",
        "accuracy.rmse(prediction_knnBasic, verbose=True)\n",
        "print(\"=====================================================================\")\n",
        "cv_results\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fn_kzijQQfn1"
      },
      "source": [
        "**KNNWithZScore**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-yYX0QiLxf3"
      },
      "source": [
        "# Creating Model using best parameters\n",
        "knnZscore_model = KNNWithZScore(k=60, sim_options={'name': 'cosine', 'user_based': False})\n",
        "\n",
        "# Training the algorithm on the trainset\n",
        "knnZscore_model.fit(trainset)\n",
        "\n",
        "# Predicting for testset\n",
        "prediction_knnZscore = knnZscore_model.test(testset)\n",
        "\n",
        "# Evaluating RMSE, MAE of algorithm KNNWithZScore on 5 split(s)\n",
        "knnZscore_cv = cross_validate(knnZscore_model, surprise_data, measures=['RMSE', 'MAE'], cv=5, verbose=True)\n",
        "\n",
        "# Storing Crossvalidation Results in dataframe\n",
        "knnZscore_df = pd.DataFrame.from_dict(knnZscore_cv)\n",
        "knnZscore_described = knnZscore_df.describe()\n",
        "knnZscore_cv_results = pd.DataFrame([['KNNWithZScore', knnZscore_described['test_rmse']['mean'], knnZscore_described['test_mae']['mean'], \n",
        "                           knnZscore_described['fit_time']['mean'], knnZscore_described['test_time']['mean']]],\n",
        "                            columns = ['Model', 'RMSE', 'MAE', 'Fit Time', 'Test Time'])\n",
        "\n",
        "cv_results = cv_results.append(knnZscore_cv_results, ignore_index=True)\n",
        "# get RMSE\n",
        "print(\"\\n\\n==================== Model Evaluation ===============================\")\n",
        "accuracy.rmse(prediction_knnZscore, verbose=True)\n",
        "print(\"=====================================================================\")\n",
        "cv_results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNArtAJWQ7gw"
      },
      "source": [
        "**KNNWithMeans User-User**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJY2S2vDLxkw"
      },
      "source": [
        "# Creating Model using best parameters\n",
        "knnMeansUU_model = KNNWithMeans(k=60, sim_options={'name': 'cosine', 'user_based': True})\n",
        "\n",
        "# Training the algorithm on the trainset\n",
        "knnMeansUU_model.fit(trainset)\n",
        "\n",
        "# Predicting for testset\n",
        "prediction_knnMeansUU = knnMeansUU_model.test(testset)\n",
        "\n",
        "# Evaluating RMSE, MAE of algorithm KNNWithMeans User-User on 5 split(s)\n",
        "knnMeansUU_cv = cross_validate(knnMeansUU_model, surprise_data, measures=['RMSE', 'MAE'], cv=5, verbose=True)\n",
        "\n",
        "# Storing Crossvalidation Results in dataframe\n",
        "knnMeansUU_df = pd.DataFrame.from_dict(knnMeansUU_cv)\n",
        "knnMeansUU_described = knnMeansUU_df.describe()\n",
        "knnMeansUU_cv_results = pd.DataFrame([['KNNWithMeans User-User', knnMeansUU_described['test_rmse']['mean'], knnMeansUU_described['test_mae']['mean'], \n",
        "                           knnMeansUU_described['fit_time']['mean'], knnMeansUU_described['test_time']['mean']]],\n",
        "                            columns = ['Model', 'RMSE', 'MAE', 'Fit Time', 'Test Time'])\n",
        "\n",
        "cv_results = cv_results.append(knnMeansUU_cv_results, ignore_index=True)\n",
        "# get RMSE\n",
        "print(\"\\n\\n==================== Model Evaluation ===============================\")\n",
        "accuracy.rmse(prediction_knnMeansUU, verbose=True)\n",
        "print(\"=====================================================================\")\n",
        "cv_results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhqJf4GGRSbf"
      },
      "source": [
        "**KNNWithMeans Item-Item**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkZapqyhLxrU"
      },
      "source": [
        "# Creating Model using best parameters\n",
        "knnMeansII_model = KNNWithMeans(k=60, sim_options={'name': 'cosine', 'user_based': False})\n",
        "\n",
        "# Training the algorithm on the trainset\n",
        "knnMeansII_model.fit(trainset)\n",
        "\n",
        "# Predicting for testset\n",
        "prediction_knnMeansII = knnMeansII_model.test(testset)\n",
        "\n",
        "# Evaluating RMSE, MAE of algorithm KNNWithMeans Item-Item on 5 split(s)\n",
        "knnMeansII_cv = cross_validate(knnMeansII_model, surprise_data, measures=['RMSE', 'MAE'], cv=5, verbose=True)\n",
        "\n",
        "# Storing Crossvalidation Results in dataframe\n",
        "knnMeansII_df = pd.DataFrame.from_dict(knnMeansII_cv)\n",
        "knnMeansII_described = knnMeansII_df.describe()\n",
        "knnMeansII_cv_results = pd.DataFrame([['KNNWithMeans Item-Item', knnMeansII_described['test_rmse']['mean'], knnMeansII_described['test_mae']['mean'], \n",
        "                           knnMeansII_described['fit_time']['mean'], knnMeansII_described['test_time']['mean']]],\n",
        "                            columns = ['Model', 'RMSE', 'MAE', 'Fit Time', 'Test Time'])\n",
        "\n",
        "cv_results = cv_results.append(knnMeansII_cv_results, ignore_index=True)\n",
        "\n",
        "# get RMSE\n",
        "print(\"\\n\\n==================== Model Evaluation ===============================\")\n",
        "accuracy.rmse(prediction_knnMeansII, verbose=True)\n",
        "print(\"=====================================================================\")\n",
        "cv_results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPyeDQm0U9ui"
      },
      "source": [
        "**COMPARING ALL RMSE AND MAE ACROSS MODELS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BeZST8kLxxO"
      },
      "source": [
        "x_algo = ['KNN Basic', 'KNNWithMeans-User-User', 'KNNWithMeans-Item-Item', 'KNN ZScore', 'SVD', 'SVD++']\n",
        "all_algos_cv = [knnBasic_cv, knnMeansUU_cv, knnMeansII_cv, knnZscore_cv, svd_cv, svdpp_cv]\n",
        "\n",
        "rmse_cv = [round(res['test_rmse'].mean(), 4) for res in all_algos_cv]\n",
        "mae_cv  = [round(res['test_mae'].mean(), 4) for res in all_algos_cv]\n",
        "\n",
        "plt.figure(figsize=(20,15))\n",
        "\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.title('Comparison of Algorithms on RMSE', loc='center', fontsize=15)\n",
        "plt.plot(x_algo, rmse_cv, label='RMSE', color='darkgreen', marker='o')\n",
        "plt.xlabel('Algorithms', fontsize=15)\n",
        "plt.ylabel('RMSE Value', fontsize=15)\n",
        "plt.legend()\n",
        "plt.grid(ls='dashed')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.title('Comparison of Algorithms on MAE', loc='center', fontsize=15)\n",
        "plt.plot(x_algo, mae_cv, label='MAE', color='navy', marker='o')\n",
        "plt.xlabel('Algorithms', fontsize=15)\n",
        "plt.ylabel('MAE Value', fontsize=15)\n",
        "plt.legend()\n",
        "plt.grid(ls='dashed')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "cv_results\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6te0or5tVYiL"
      },
      "source": [
        "**MODEL EVALUATION:**\n",
        "\n",
        "From above algorithm comparisons plots we can infer the followings:\n",
        "\n",
        "1.   RMSE : we can see that SVD++ is giving the best RMSE values\n",
        "2.   MAE : Here SVD++ and KNNWithMean-User-User both are giving the best MAE value\n",
        "3.   SVD++ is showing the best RMSE in Matrix Factorization Based Algorithms.\n",
        "4.   KNNWithMeans is giving the best RMSE in Collaborative Filtering Algorithms.\n",
        "5.  If compare SVD and SVD++ then can notice that RMSE and MAE value of SVD is slightly differs from the SVD++ but the Fit Time and Test Time taken by SVD is significant less(12 times) than SVD++. So, we will proceed with SVD got get top-k recommendations\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2N_7JdxZYuST"
      },
      "source": [
        "**MODEL DEPLOYMENT**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bTzP2IsLx28"
      },
      "source": [
        "top_n = defaultdict(list)\n",
        "def get_top_n(predictions, n=k):\n",
        "    # First map the predictions to each user.\n",
        "    top_n = defaultdict(list)\n",
        "    for uid, iid, true_r, est, _ in predictions:\n",
        "        top_n[uid].append((iid, est))\n",
        "\n",
        "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
        "    for uid, user_ratings in top_n.items():\n",
        "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
        "        top_n[uid] = user_ratings[:n]\n",
        "\n",
        "    return top_n\n",
        "\n",
        "top_n = get_top_n(predictions_svd, n=k)\n",
        "top_n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXw69NTqZf5J"
      },
      "source": [
        "**NOTE:**\n",
        "\n",
        "The above list shows the model recommendations the \"TOP 5\" products for each user. There are some cases in which less than 5 products are recommended as the model is not able to find the appropriate number of neighbors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWIy5HqzaBIi"
      },
      "source": [
        "def precision_recall_at_k(predictions, k=5, threshold=3.5):\n",
        "    '''Return precision and recall at k metrics for each user.'''\n",
        "\n",
        "    # First map the predictions to each user.\n",
        "    user_est_true = defaultdict(list)\n",
        "    for uid, _, true_r, est, _ in predictions:\n",
        "        user_est_true[uid].append((est, true_r))\n",
        "\n",
        "    precisions = dict()\n",
        "    recalls = dict()\n",
        "    for uid, user_ratings in user_est_true.items():\n",
        "\n",
        "        # Sort user ratings by estimated value\n",
        "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
        "\n",
        "        # Number of relevant items\n",
        "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
        "\n",
        "        # Number of recommended items in top k\n",
        "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
        "\n",
        "        # Number of relevant and recommended items in top k\n",
        "        n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold))\n",
        "                              for (est, true_r) in user_ratings[:k])\n",
        "\n",
        "        # Precision@K: Proportion of recommended items that are relevant\n",
        "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 1\n",
        "\n",
        "        # Recall@K: Proportion of relevant items that are recommended\n",
        "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 1\n",
        "\n",
        "    return precisions, recalls\n",
        "\n",
        "\n",
        "kf = KFold(n_splits=5)\n",
        "svd_model = SVD(n_epochs=20, lr_all=0.005, reg_all=0.2)\n",
        "precs = []\n",
        "recalls = []\n",
        "\n",
        "for trainset, testset in kf.split(surprise_data):\n",
        "    svd_model.fit(trainset)\n",
        "    predictions = svd_model.test(testset)\n",
        "    precisions, recalls = precision_recall_at_k(predictions, k=5, threshold=3.5)\n",
        "\n",
        "    # Precision and recall can then be averaged over all users\n",
        "    print('Precision : ', sum(prec for prec in precisions.values()) / len(precisions))\n",
        "    print('Recalls : ',sum(rec for rec in recalls.values()) / len(recalls))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eY2Cpzim5RZo"
      },
      "source": [
        "pickle.dump(svd_model,open('mostrelevant.pkl','wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGrGEUqSau-c"
      },
      "source": [
        "**Comment:** Precision and Recall have been calculated at k=5. \n",
        "\n",
        " Precision and Recall are binary metrics used to evaluate models with binary output. We need a way to translate our numerical problem (ratings usually from 1 to 5) into a binary problem (relevant and not relevant items). To do the translation we assume that any true rating above 3.5 corresponds to a relevant item and any true rating below 3.5 is irrelevant.\n",
        "\n",
        "Precision at 5 within the TOP 5 recommendations is alomost 85%. This means that 86% of the recommendation are relevent to the users.\n",
        "Recall at 5 within the TOP 5 recommendations problem is almost 95%. This means that 95% of the total number of the relevent products appear in the top-k result."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwAdUamYavVP"
      },
      "source": [
        "**CONCLUSION**\n",
        "\n",
        "- EDA shows us that most of the customers give a rating of \"5\". This leads us to the conclusion that customers are very satisfied with their purchase. It may need some investigation to see if some bots or mandatory feedback at lower ratings are causing the majority to give a top rating of \"5\"\n",
        "\n",
        "- Subset of users who have provided 50 or more ratings and products which have received more than 10 ratings have been used to remove outliers and overcome Grey Sheep issue.\n",
        "\n",
        "- Popularity Model - shows the TOP 5 recommended products irrespective of the user. The same 5 product will be recommended for every user.\n",
        "\n",
        "- 'Matrix Factorization Based Algorithms' & 'k-NN Based Algorithms' were used to build Collaborative Filtering model.\n",
        "\n",
        "- SVD++ yields the lowest RMSE which is slightly better than SVD but computational time of SVD++ is 12 times greater than SVD. SVD can be used to get the recommended products.\n",
        "\n",
        "- Precision which is almost 86%. which can be interpreted as 86% of the recommendations are actually relevant to the user.\n",
        "\n",
        "- Recall is at 96% which can be interpreted as percent of the relevant items were recommended in the top-k items."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66BUxovdbWXp"
      },
      "source": [
        "!pip install colabcode\n",
        "!pip install fastapi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cC0mAyX1wI-n"
      },
      "source": [
        "import uvicorn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJsHtMvxxF8M"
      },
      "source": [
        "from pydantic import BaseModel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1wZOMuibXa0"
      },
      "source": [
        "from colabcode import ColabCode"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qI-eNsCXg7J_"
      },
      "source": [
        "from fastapi import FastAPI"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVCA6AIfF8mG"
      },
      "source": [
        "from typing import Optional"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBCXzKmWbmaj"
      },
      "source": [
        "#cc = ColabCode(port=12000, password=None, authtoken=None, mount_drive=False, code=False, lab=False)\n",
        "cc = ColabCode(port=12000, code=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCDzJLf_bymq"
      },
      "source": [
        "app = FastAPI()\n",
        "\n",
        "@app.get(\"/\")\n",
        "async def read_root():\n",
        "  return {\"PRODUCT RECOMMENDER\":\"APP2\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuioQ40-6xLK"
      },
      "source": [
        "app.main:app"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPSY5rJAc5O9"
      },
      "source": [
        "cc.run_app(app=app)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TaAWOMA2JSC4"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yMISn3-b53v"
      },
      "source": [
        "%%writefile models.py\n",
        "from pydantic import BaseModel, conlist\n",
        "from typing import List\n",
        "\n",
        "class electronics_data(BaseModel)\n",
        "data: List[conlist(float, min_items=1, max_items=1)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvqTI11JhXI9"
      },
      "source": [
        "import pickle\n",
        "import logging\n",
        "from fastapi import FastAPI"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEzsmhKTpeuP"
      },
      "source": [
        "pickle.dump(svd_model,open('mostrelevant.pkl','wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUT6vJv8uJWB"
      },
      "source": [
        "%%writefile models.py\n",
        "from pydantic import BaseModel, conlist\n",
        "from typing import List\n",
        "\n",
        "class electronics_data(BaseModel):\n",
        "  userId: object \n",
        "  productId: object \n",
        "  Rating: float64\n",
        "  timestamp: float64\n",
        "data: List[conlist(float, min_items=1, max_items=1)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OZOI4EI27FP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3lenRM4vH6j"
      },
      "source": [
        "import pickle\n",
        "import logging\n",
        "from fastapi import FastApi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAoROwHscryN"
      },
      "source": [
        "from fastapi import FastAPI\n",
        "\n",
        "app = FastAPI(title=\"Model Deployment\", description=\"with FastAPI and Colab\", version=\"1.0\")\n",
        "\n",
        "##Initialize logging\n",
        "#my_logger = logging.getLogger()\n",
        "#my_logger.setLevel(logging.DEBUG)\n",
        "#logging.basicConfig(level=logging.DEBUG, filename='logs.log')\n",
        "\n",
        "model = None\n",
        "\n",
        "@app.on_event(\"startup\")\n",
        "def load_model():\n",
        "    global model\n",
        "    model = pickle.load(open(\"mostpopular.pkl\", \"rb\"))\n",
        "\n",
        "@app.post(\"/api\", tags=[\"prediction\"])\n",
        "async def get_predictions \n",
        "data= dict(popularity_recommendations)['data']:\n",
        "        print(data)\n",
        "        prediction = list(map(lambda x: popularity_recommendations_types[x], model.predict(data).tolist()))\n",
        "        log_proba = model.predict_log_proba(data).tolist()\n",
        "        return {\"prediction\": prediction, \"log_proba\": log_proba}\n",
        "\n",
        "    except:\n",
        "        my_logger.error(\"Something went wrong!\")\n",
        "        return {\"prediction\": \"error\"}"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}